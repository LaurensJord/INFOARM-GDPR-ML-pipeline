{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487e59d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a99d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statsmodels version: 0.14.6\n",
      "Numpy version: 2.3.3\n",
      "Pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import statsmodels as sm\n",
    "\n",
    "from statsmodels.stats.contingency_tables import mcnemar, cochrans_q\n",
    "\n",
    "\n",
    "print(\"Statsmodels version:\", sm.__version__)\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b0cd8",
   "metadata": {},
   "source": [
    "# Classification performance results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ca39fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       8\n",
      "1       8\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2475    1\n",
      "2476    7\n",
      "2477    0\n",
      "2478    5\n",
      "2479    5\n",
      "Name: label, Length: 2480, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ground truth labels\n",
    "y_true = pd.read_csv('artifacts/bert/eval_predictions.csv')['label']\n",
    "\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888a1d3",
   "metadata": {},
   "source": [
    "## BERT vs RoBERTa vs BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1805b711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df          2479\n",
      "pvalue      4.80109917232847e-192\n",
      "statistic   5175.821077702536\n"
     ]
    }
   ],
   "source": [
    "y_pred_bert = pd.read_csv('artifacts/bert/eval_predictions.csv')['y_pred']\n",
    "y_pred_roberta = pd.read_csv('artifacts/roberta/eval_predictions.csv')['y_pred']\n",
    "y_pred_bilstm = pd.read_csv('artifacts/bilstm/eval_predictions.csv')['y_pred']\n",
    "\n",
    "cochrans_q_result = cochrans_q(\n",
    "    np.vstack([y_pred_bert, y_pred_roberta, y_pred_bilstm])\n",
    ")\n",
    "\n",
    "print(cochrans_q_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5902a694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.043529866418422\n"
     ]
    }
   ],
   "source": [
    "Q = cochrans_q_result.statistic\n",
    "n = 2480\n",
    "k = 3\n",
    "\n",
    "R = (Q - (k -1)) / ((k - 1) * (n - 1))\n",
    "\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c5a1c1",
   "metadata": {},
   "source": [
    "### Homogeneity of covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "578ac1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15190032, 0.1087049 , 0.07084201],\n",
       "       [0.1087049 , 0.16507551, 0.07029516],\n",
       "       [0.07084201, 0.07029516, 0.2244647 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(np.vstack([y_pred_bert == y_true, y_pred_roberta == y_true, y_pred_bilstm == y_true]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82909d",
   "metadata": {},
   "source": [
    "## BERT vs RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2380b0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predictions\n",
      "0       8\n",
      "1       8\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2475    1\n",
      "2476    7\n",
      "2477    0\n",
      "2478    5\n",
      "2479    5\n",
      "Name: y_pred, Length: 2480, dtype: int64\n",
      "RoBERTa predictions\n",
      "0       8\n",
      "1       8\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2475    1\n",
      "2476    7\n",
      "2477    0\n",
      "2478    5\n",
      "2479    5\n",
      "Name: y_pred, Length: 2480, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# bert and roberta predictions\n",
    "y_pred_bert = pd.read_csv('artifacts/bert/eval_predictions.csv')['y_pred']\n",
    "y_pred_roberta = pd.read_csv('artifacts/roberta/eval_predictions.csv')['y_pred']\n",
    "\n",
    "print(\"BERT predictions\")\n",
    "print(y_pred_bert)\n",
    "\n",
    "print(\"RoBERTa predictions\")\n",
    "print(y_pred_roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57b09f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RoBERTa Correct</th>\n",
       "      <th>RoBERTa Wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BERT Correct</th>\n",
       "      <td>n_11</td>\n",
       "      <td>n_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERT Wrong</th>\n",
       "      <td>n_01</td>\n",
       "      <td>n_00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             RoBERTa Correct RoBERTa Wrong\n",
       "BERT Correct            n_11          n_10\n",
       "BERT Wrong              n_01          n_00"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contingency table agreement template\n",
    "contingency_table = pd.DataFrame(\n",
    "    [['n_11', 'n_10'],\n",
    "     ['n_01', 'n_00']],\n",
    "    index=['BERT Correct', 'BERT Wrong'],\n",
    "    columns=['RoBERTa Correct', 'RoBERTa Wrong']\n",
    ")\n",
    "\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a3b05f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1866  151]\n",
      " [  97  366]]\n",
      "pvalue      0.0007640413512558077\n",
      "statistic   11.326612903225806\n"
     ]
    }
   ],
   "source": [
    "n_11 = np.sum((y_pred_bert == y_true) & (y_pred_roberta == y_true))\n",
    "n_10 = np.sum((y_pred_bert == y_true) & (y_pred_roberta != y_true))\n",
    "n_01 = np.sum((y_pred_bert != y_true) & (y_pred_roberta == y_true))\n",
    "n_00 = np.sum((y_pred_bert != y_true) & (y_pred_roberta != y_true))\n",
    "\n",
    "table = np.array([[n_11, n_10],\n",
    "                  [n_01, n_00]])\n",
    "\n",
    "print(table)\n",
    "\n",
    "mcnemar_result = mcnemar(table, exact=False)\n",
    "\n",
    "print(mcnemar_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64f3e136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect size (odds ratio) between BERT and RoBERTa: 1.556701030927835\n"
     ]
    }
   ],
   "source": [
    "bert_roberta_odds_ratio = n_10 / n_01\n",
    "\n",
    "print(\"Effect size (odds ratio) between BERT and RoBERTa:\", bert_roberta_odds_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "891e25c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for odds ratio between BERT and RoBERTa: (1.2062655759068208, 2.0089424319930824)\n"
     ]
    }
   ],
   "source": [
    "SE = math.sqrt(1/n_10 + 1/n_01)\n",
    "lower_ci_bert_roberta = math.exp(math.log(bert_roberta_odds_ratio) - 1.96 * SE)\n",
    "upper_ci_bert_roberta = math.exp(math.log(bert_roberta_odds_ratio) + 1.96 * SE)\n",
    "\n",
    "print(f\"95% CI for odds ratio between BERT and RoBERTa: ({lower_ci_bert_roberta}, {upper_ci_bert_roberta})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8b18fe",
   "metadata": {},
   "source": [
    "## BERT vs BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa3b275b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predictions\n",
      "0       8\n",
      "1       8\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2475    1\n",
      "2476    7\n",
      "2477    0\n",
      "2478    5\n",
      "2479    5\n",
      "Name: y_pred, Length: 2480, dtype: int64\n",
      "RoBERTa predictions\n",
      "0       2\n",
      "1       0\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "2475    0\n",
      "2476    7\n",
      "2477    0\n",
      "2478    5\n",
      "2479    5\n",
      "Name: y_pred, Length: 2480, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# bert and bilstm predictions\n",
    "y_pred_bert = pd.read_csv('artifacts/bert/eval_predictions.csv')['y_pred']\n",
    "y_pred_bilstm = pd.read_csv('artifacts/bilstm/eval_predictions.csv')['y_pred']\n",
    "\n",
    "print(\"BERT predictions\")\n",
    "print(y_pred_bert)\n",
    "\n",
    "print(\"RoBERTa predictions\")\n",
    "print(y_pred_bilstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a3aee5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BiLSTM Correct</th>\n",
       "      <th>BiLSTM Wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BERT Correct</th>\n",
       "      <td>n_11</td>\n",
       "      <td>n_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERT Wrong</th>\n",
       "      <td>n_01</td>\n",
       "      <td>n_00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             BiLSTM Correct BiLSTM Wrong\n",
       "BERT Correct           n_11         n_10\n",
       "BERT Wrong             n_01         n_00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contingency table agreement template\n",
    "contingency_table = pd.DataFrame(\n",
    "    [['n_11', 'n_10'],\n",
    "     ['n_01', 'n_00']],\n",
    "    index=['BERT Correct', 'BERT Wrong'],\n",
    "    columns=['BiLSTM Correct', 'BiLSTM Wrong']\n",
    ")\n",
    "\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74a366a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1507  510]\n",
      " [ 130  333]]\n",
      "pvalue      9.73091609290084e-51\n",
      "statistic   224.4390625\n"
     ]
    }
   ],
   "source": [
    "n_11 = np.sum((y_pred_bert == y_true) & (y_pred_bilstm == y_true))\n",
    "n_10 = np.sum((y_pred_bert == y_true) & (y_pred_bilstm != y_true))\n",
    "n_01 = np.sum((y_pred_bert != y_true) & (y_pred_bilstm == y_true))\n",
    "n_00 = np.sum((y_pred_bert != y_true) & (y_pred_bilstm != y_true))\n",
    "\n",
    "table = np.array([[n_11, n_10],\n",
    "                  [n_01, n_00]])\n",
    "\n",
    "print(table)\n",
    "\n",
    "mcnemar_result = mcnemar(table, exact=False)\n",
    "\n",
    "print(mcnemar_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7246b291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect size (odds ratio) between BERT and BiLSTM: 3.923076923076923\n"
     ]
    }
   ],
   "source": [
    "bert_bilstm_odds_ratio = n_10 / n_01\n",
    "\n",
    "print(\"Effect size (odds ratio) between BERT and BiLSTM:\", bert_bilstm_odds_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00a22381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for odds ratio between BERT and BiLSTM: (3.2358963906250886, 4.756188297303813)\n"
     ]
    }
   ],
   "source": [
    "SE = math.sqrt(1/n_10 + 1/n_01)\n",
    "lower_ci_bert_bilstm = math.exp(math.log(bert_bilstm_odds_ratio) - 1.96 * SE)\n",
    "upper_ci_bert_bilstm = math.exp(math.log(bert_bilstm_odds_ratio) + 1.96 * SE)\n",
    "\n",
    "print(f\"95% CI for odds ratio between BERT and BiLSTM: ({lower_ci_bert_bilstm}, {upper_ci_bert_bilstm})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b86650b",
   "metadata": {},
   "source": [
    "## RoBERTa vs BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3bd5181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT predictions\n",
      "0       8\n",
      "1       8\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2475    1\n",
      "2476    7\n",
      "2477    0\n",
      "2478    5\n",
      "2479    5\n",
      "Name: y_pred, Length: 2480, dtype: int64\n",
      "BiLSTM predictions\n",
      "0       2\n",
      "1       0\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "2475    0\n",
      "2476    7\n",
      "2477    0\n",
      "2478    5\n",
      "2479    5\n",
      "Name: y_pred, Length: 2480, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# roberta and bilstm predictions\n",
    "y_pred_roberta = pd.read_csv('artifacts/roberta/eval_predictions.csv')['y_pred']\n",
    "y_pred_bilstm = pd.read_csv('artifacts/bilstm/eval_predictions.csv')['y_pred']\n",
    "\n",
    "print(\"BERT predictions\")\n",
    "print(y_pred_roberta)\n",
    "\n",
    "print(\"BiLSTM predictions\")\n",
    "print(y_pred_bilstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e03478b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BiLSTM Correct</th>\n",
       "      <th>BiLSTM Wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RoBERTa Correct</th>\n",
       "      <td>n_11</td>\n",
       "      <td>n_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa Wrong</th>\n",
       "      <td>n_01</td>\n",
       "      <td>n_00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                BiLSTM Correct BiLSTM Wrong\n",
       "RoBERTa Correct           n_11         n_10\n",
       "RoBERTa Wrong             n_01         n_00"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contingency table agreement template\n",
    "contingency_table = pd.DataFrame(\n",
    "    [['n_11', 'n_10'],\n",
    "     ['n_01', 'n_00']],\n",
    "    index=['RoBERTa Correct', 'RoBERTa Wrong'],\n",
    "    columns=['BiLSTM Correct', 'BiLSTM Wrong']\n",
    ")\n",
    "\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa68d3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1470  493]\n",
      " [ 167  350]]\n",
      "pvalue      1.1101260240194846e-36\n",
      "statistic   160.03787878787878\n"
     ]
    }
   ],
   "source": [
    "n_11 = np.sum((y_pred_roberta == y_true) & (y_pred_bilstm == y_true))\n",
    "n_10 = np.sum((y_pred_roberta == y_true) & (y_pred_bilstm != y_true))\n",
    "n_01 = np.sum((y_pred_roberta != y_true) & (y_pred_bilstm == y_true))\n",
    "n_00 = np.sum((y_pred_roberta != y_true) & (y_pred_bilstm != y_true))\n",
    "\n",
    "table = np.array([[n_11, n_10],\n",
    "                  [n_01, n_00]])\n",
    "\n",
    "print(table)\n",
    "\n",
    "mcnemar_result = mcnemar(table, exact=False)\n",
    "\n",
    "print(mcnemar_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba8d1ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect size (odds ratio) between RoBERTa and BiLSTM: 2.9520958083832336\n"
     ]
    }
   ],
   "source": [
    "roberta_bilstm_odds_ratio = n_10 / n_01\n",
    "\n",
    "print(\"Effect size (odds ratio) between RoBERTa and BiLSTM:\", roberta_bilstm_odds_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d7a1770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for odds ratio between RoBERTa and BiLSTM: (2.476949587943646, 3.518387981851867)\n"
     ]
    }
   ],
   "source": [
    "SE = math.sqrt(1/n_10 + 1/n_01)\n",
    "lower_ci_roberta_bilstm = math.exp(math.log(roberta_bilstm_odds_ratio) - 1.96 * SE)\n",
    "upper_ci_roberta_bilstm = math.exp(math.log(roberta_bilstm_odds_ratio) + 1.96 * SE)\n",
    "\n",
    "print(f\"95% CI for odds ratio between RoBERTa and BiLSTM: ({lower_ci_roberta_bilstm}, {upper_ci_roberta_bilstm})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82622874",
   "metadata": {},
   "source": [
    "# Computational performance results for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d85dd74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT training CPU total seconds:  2149.36\n",
      "RoBERTa training CPU total seconds:  2155.84\n",
      "BiLSTM training CPU total seconds:  17.19\n"
     ]
    }
   ],
   "source": [
    "# traning of computational performance\n",
    "\n",
    "training_bilstm_computational_performance = {\"tag\": \"Train BiLSTM\", \"wall_time_sec\": 12.607763934999639, \"cpu_user_sec\": 14.98, \"cpu_system_sec\": 2.21, \"ram_delta_mb\": 714.87890625, \"gpu_peak_mem_mb\": 659.55126953125}\n",
    "training_bert_computational_performance = {\"tag\": \"TRAINING - BERT - OPP115\", \"wall_time_sec\": 2156.2268697129994, \"cpu_user_sec\": 2144.84, \"cpu_system_sec\": 4.52, \"ram_delta_mb\": 1324.76171875, \"gpu_peak_mem_mb\": 7489.453125}\n",
    "training_roberta_computational_performance = {\"tag\": \"TRAINING - RoBERTa - OPP115\", \"wall_time_sec\": 2161.9818342470007, \"cpu_user_sec\": 2150.05, \"cpu_system_sec\": 5.79, \"ram_delta_mb\": 1342.984375, \"gpu_peak_mem_mb\": 7664.5234375}\n",
    "\n",
    "training_bert_cpu_total = training_bert_computational_performance['cpu_user_sec'] + training_bert_computational_performance['cpu_system_sec']\n",
    "training_roberta_cpu_total = training_roberta_computational_performance['cpu_user_sec'] + training_roberta_computational_performance['cpu_system_sec']\n",
    "training_bilstm_cpu_total = training_bilstm_computational_performance['cpu_user_sec'] + training_bilstm_computational_performance['cpu_system_sec']\n",
    "\n",
    "print(\"BERT training CPU total seconds: \", training_bert_cpu_total)\n",
    "print(\"RoBERTa training CPU total seconds: \", training_roberta_cpu_total)\n",
    "print(\"BiLSTM training CPU total seconds: \", training_bilstm_cpu_total)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
